{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SA - Logistic Regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QggINTnPLqC",
        "colab_type": "text"
      },
      "source": [
        "### Sentiment Analysis using Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Js5uGTlDaSFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mag-4vebPQ1s",
        "colab_type": "code",
        "outputId": "299ab0d6-e1c6-4423-fcbd-c7c6cda9873d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hg1SRMqwPSP_",
        "colab_type": "code",
        "outputId": "7f3634fb-0167-45c5-d052-a31255b6d441",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# Load data\n",
        "PATH = '/content/drive/My Drive/Big Data Analytics - Project/Data/'\n",
        "data = pd.read_csv(PATH + 'AmazonCustomerReviewsK3.csv', delimiter=',', index_col=None, error_bad_lines=False)\n",
        "data.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['marketplace', 'customer_id', 'review_id', 'product_id',\n",
              "       'product_parent', 'product_title', 'product_category', 'star_rating',\n",
              "       'helpful_votes', 'total_votes', 'vine', 'verified_purchase',\n",
              "       'review_headline', 'review_body', 'review_date', 'body_polarity',\n",
              "       'label'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTK-q-DUPYp_",
        "colab_type": "code",
        "outputId": "d801864c-708e-4b30-f2f9-cb92c8a1bf4c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "data['label'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    632337\n",
              "1    232244\n",
              "0    135419\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mpgz4Fl9aDVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# balance dataset - 250000 samples for each class\n",
        "from sklearn.utils import resample\n",
        "\n",
        "N_samples = 250000\n",
        "# Separate majority and minority classes\n",
        "data_2 = data[data.label==2]  # majority\n",
        "\n",
        "data_1 = data[data.label==1]  # minority\n",
        "data_0 = data[data.label==0]  # minority\n",
        " \n",
        "# Downsample majority class\n",
        "data_2 = resample(data_2, \n",
        "                  replace=False, # sample without replacement\n",
        "                  n_samples=N_samples,\n",
        "                  random_state=8)\n",
        "\n",
        "# Upsample minority classes\n",
        "data_1 = resample(data_1, \n",
        "                  replace=True, # sample with replacement\n",
        "                  n_samples=N_samples,\n",
        "                  random_state=8)\n",
        "data_0 = resample(data_0, \n",
        "                  replace=True, # sample with replacement\n",
        "                  n_samples=N_samples,\n",
        "                  random_state=8)\n",
        " \n",
        "# Combine classes\n",
        "data = pd.concat([data_2, data_1, data_0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJU-XF_LelVl",
        "colab_type": "code",
        "outputId": "db9110a7-8324-4c48-e598-234d477196d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "data['label'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    250000\n",
              "1    250000\n",
              "0    250000\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFPMeKCwPdak",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# split into train and test data\n",
        "from sklearn.utils import shuffle\n",
        "N_split = 600000\n",
        "data_X = pd.DataFrame(data, columns = ['review_body']).fillna('')\n",
        "data_y = pd.DataFrame(data, columns = ['label']).fillna('')\n",
        "data_X = data_X.values.flatten()\n",
        "data_y = data_y.values.flatten()\n",
        "data_X, data_y = shuffle(data_X, data_y)\n",
        "X_train, y_train = data_X[:N_split], data_y[:N_split]\n",
        "X_test, y_test = data_X[N_split:], data_y[N_split:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVmaqWPUQ65m",
        "colab_type": "code",
        "outputId": "fe699118-3a0f-4487-b922-894937252fc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Convert reviews to BoW using CountVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vectorizer = CountVectorizer()\n",
        "X_train = vectorizer.fit_transform(X_train)\n",
        "X_test = vectorizer.transform(X_test)\n",
        "\n",
        "print(f'Vocabulary size: {len(vectorizer.vocabulary_)}')\n",
        "print(f'X_train:\\n{repr(X_train)}')\n",
        "print(f'X_test: \\n{repr(X_test)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size: 279028\n",
            "X_train:\n",
            "<600000x279028 sparse matrix of type '<class 'numpy.int64'>'\n",
            "\twith 13977977 stored elements in Compressed Sparse Row format>\n",
            "X_test: \n",
            "<150000x279028 sparse matrix of type '<class 'numpy.int64'>'\n",
            "\twith 3459236 stored elements in Compressed Sparse Row format>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "er_ZFX2DSzkO",
        "colab_type": "code",
        "outputId": "51990f97-4616-4f22-9683-e85d8fa7504e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "feature_names = vectorizer.get_feature_names()\n",
        "print(f'Number of features: {len(feature_names)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of features: 279028\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4-KRCBZXGS5",
        "colab_type": "text"
      },
      "source": [
        "####Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBvsCKgJUm8g",
        "colab_type": "code",
        "outputId": "01257a23-a085-40c0-befa-5bd261b6b522",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# perform grid search and cross validate data to prevent over-fitting\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "param_grid = {'C': [0.01, 0.1, 1]}\n",
        "grid = GridSearchCV(LogisticRegression(max_iter=500, class_weight='balanced'), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(f'Best cross-validation score: {round(grid.best_score_)}')\n",
        "print(f'Best parameters: {grid.best_params_}' )\n",
        "print(f'Best estimator: {grid.best_estimator_}')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best cross-validation score: 1.0\n",
            "Best parameters: {'C': 1}\n",
            "Best estimator: LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=500,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb_DEJyIXf6c",
        "colab_type": "code",
        "outputId": "ebdac00b-b0e7-4cbd-b452-b5759b3ec007",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "LogReg_clf = grid.best_estimator_\n",
        "LogReg_clf.fit(X_train, y_train)\n",
        "LogReg_clf.predict(X_test)\n",
        "\n",
        "print(f'Score: {round(LogReg_clf.score(X_test, y_test))}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score: 1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JvRlXrh_b_jY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Pickle classifier\n",
        "def create_pickle(c, file_name): \n",
        "    save_classifier = open(file_name, 'wb')\n",
        "    pickle.dump(c, save_classifier)\n",
        "    save_classifier.close()\n",
        "\n",
        "# save model and vectorizer\n",
        "create_pickle(LogReg_clf, PATH + 'models/LogReg_SA_K3.pickle')\n",
        "create_pickle(vectorizer, PATH + 'models/LogReg_SA_K3_vectorizer.pickle')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72eCbTdCcLOE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load model\n",
        "def load_model(file_path):\n",
        "  clf_f = open(file_path, 'rb')\n",
        "  clf = pickle.load(clf_f)\n",
        "  clf_f.close()\n",
        "  return clf\n",
        "\n",
        "# Logistic Regression Classifier\n",
        "LogReg_clf = load_model(PATH + 'models/LogReg_SA_K3.pickle')\n",
        "\n",
        "# Vectorizer\n",
        "with open(PATH + 'models/LogReg_SA_K3_vectorizer.pickle', 'rb') as f:\n",
        "    vectorizer = pickle.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1JUL_ymcd0i",
        "colab_type": "code",
        "outputId": "d65940c0-1b7c-491f-82f0-1c8e2e96791f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "# Sentiment analysis\n",
        "\n",
        "neg = ['This item is very bad', 'This item sucks']\n",
        "pos = ['I loved the product', 'did not work, hate it']\n",
        "neutral = ['product was okay, expected more']\n",
        "\n",
        "print(f'Negative comments: {LogReg_clf.predict(vectorizer.transform(neg))}')\n",
        "print(f'Positive comments: {LogReg_clf.predict(vectorizer.transform(pos))}')\n",
        "print(f'Neutral comments: {LogReg_clf.predict(vectorizer.transform(neutral))}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Negative comments: [0 0]\n",
            "Positive comments: [2 0]\n",
            "Neutral comments: [1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3Lp6J03fAIJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}